{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0f8a7d-a8cd-48e2-b211-f2d6365cdd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_to_hf import *\n",
    "from models.gpt2 import *\n",
    "from presets import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2ae698-6e7f-40c4-87ac-2c64ca3d64d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08c0ed-742e-46ac-baac-60a20c22e20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2591232a-591b-4402-bec7-92db288b8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='gpt2'\n",
    "config = model_presets['gpt2']['124m']\n",
    "ckp_path = './log/model_19072.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2306a91b-03e1-4202-bc2a-053dcc48ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = convert_to_hf(model_name,config,ckp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef874d75-09ac-463e-9d4f-169fe9e523da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef73b36f-d162-4257-9d38-a5c489dd4468",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./hf_model-124m_19072\",safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31895a38-2a21-4e22-9368-bce0a41c9b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./hf_model-124m_19072/tokenizer_config.json',\n",
       " './hf_model-124m_19072/special_tokens_map.json',\n",
       " './hf_model-124m_19072/vocab.json',\n",
       " './hf_model-124m_19072/merges.txt',\n",
       " './hf_model-124m_19072/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./hf_model-124m_19072\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1c860e3-768c-44b6-a69a-0280e34730c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a9db71-67f6-47f3-bb6e-2a59035d9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=\"./hf_model-124m_19072\",device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d211ee9a-85a3-4a96-a2e6-79a2a33050cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"OpenAI is \"\n",
    "generated_text = generator(prompt, max_length=50, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a82868-d08c-42ad-9bf5-a2c4f12c2eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'OpenAI is  a non-profit organization that is dedicated to the development of AI-based solutions for the AI industry. The AI-based solutions are designed to solve problems that are difficult to solve by humans. The AI-based solutions are designed'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa446a0-d3d8-4062-8032-71c7937b9265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
